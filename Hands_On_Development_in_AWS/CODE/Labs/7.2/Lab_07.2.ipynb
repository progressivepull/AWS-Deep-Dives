{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7406d8f7-04b7-4fb5-9901-4c84d7b87eb6",
   "metadata": {},
   "source": [
    "# Sagemaker Pipeline with Preprocess and Train Steps\n",
    "The following python application will create a pipeline that processes data from an S3 bucket, stores in the same bucket and then trains a model on that data.\n",
    "\n",
    "The file in the repository/Datasets/pipeline-dataset-dirty/dirty.csv is missing 10 age values, lines 10-14 and 4980-4984.\n",
    "As a result of the preprocessing script, the first 5 missing value lines will end up in the training input and the latter 5 will end up in the validation input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18434d0-1ed2-4e0f-8d31-e1d822bce6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "\n",
    "# Initialize session\n",
    "### Local\n",
    "# from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "# local_pipeline_session = LocalPipelineSession()\n",
    "# pipeline_session = local_pipeline_session\n",
    "### Remote\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "role = \"INSERT_ARN\"\n",
    "s3_bucket = \"INSERT_BUCKET\"\n",
    "\n",
    "# Define Parameters\n",
    "xgb_image_uri = image_uris.retrieve(framework='xgboost',region='us-east-1', version='1.7-1')\n",
    "input_process_path = f\"s3://{s3_bucket}/pipeline-dataset-dirty/dirty.csv\"\n",
    "model_path = f\"s3://{s3_bucket}/pipeline-model/\"\n",
    "\n",
    "\n",
    "\n",
    "#### Processing Step for Feature Engineering\n",
    "####  See example at the following URL for a more in-depth demonstration of feature engineering preprocessing\n",
    "####    https://github.com/aws/amazon-sagemaker-examples/blob/4534bff4b5b5062af5789d98c4ddca01b0cb5d1f/sagemaker-pipelines/tabular/abalone_build_train_deploy/sagemaker-pipelines-preprocess-train-evaluate-batch-transform.ipynb\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"sklearn-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_process_path, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "    ],\n",
    "    code=\"preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"DataProcess\", step_args=processor_args)\n",
    "\n",
    "\n",
    "#### Train Step\n",
    "xgb_train = Estimator(\n",
    "    image_uri=xgb_image_uri,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:squarederror\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    subsample=0.7\n",
    ")\n",
    "\n",
    "# Use estimator directly in the TrainingStep insteaad of calling fit()\n",
    "step_train = TrainingStep(\n",
    "    name=\"Train\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    image_uri=xgb_image_uri,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    role=role,\n",
    ")\n",
    "step_create_model = ModelStep(\n",
    "    name=\"CreateModel\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\"),\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_name = \"ADGUPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[step_process, step_train, step_create_model],\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e892f-a043-42b1-b379-65498e4c0a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
