{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4b18e4-6a44-4f9b-bb5f-0121e06f1a68",
   "metadata": {},
   "source": [
    "# Asynchronous Inference\n",
    "\n",
    "_NOTE_: Execute this after the _batch example as we'll reuse the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85792847-db8f-4c0f-aca7-5e78e90a5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploy Model from Saved Assets, enable asynch\n",
    "\n",
    "import boto3\n",
    "import time, random, uuid\n",
    "from sagemaker import Model\n",
    "from sagemaker import image_uris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "s3_bucket = \"INSERT_S3_BUCKET\"\n",
    "sagemaker_role = \"INSERT_ARN\"\n",
    "model_name = \"INSERT_MODEL_NAME\"\n",
    "s3_async_output_prefix = \"async-inference-results\" \n",
    "s3_async_input_key = \"INSERT_INPUT_KEY\"\n",
    "\n",
    "# Initialize Boto3 SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=\"us-east-1\")\n",
    "xgboost_image_uri = image_uris.retrieve(framework='xgboost',region='us-east-1', version='1.7-1')\n",
    "\n",
    "# Model & Endpoint Configurations\n",
    "uniqueID = uuid.uuid4().hex\n",
    "endpoint_config_name = f\"async-endpoint-config-{uniqueID}\"\n",
    "endpoint_name = f\"async-endpoint-{uniqueID}\"\n",
    "\n",
    "# Create Endpoint Configuration with Asynchronous Inference\n",
    "print(\"Creating asynchronous endpoint configuration...\")\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"XGBoostVariant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.m5.large\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{s3_bucket}/{s3_async_output_prefix}\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Deploy the Model as an Asynchronous Endpoint\n",
    "print(\"Deploying model as an asynchronous endpoint...\")\n",
    "sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(f\"Asynchronous endpoint '{endpoint_name}' is being created.\")\n",
    "\n",
    "# Wait for endpoint to be ready\n",
    "print(\"Waiting for endpoint to be ready...\")\n",
    "while True:\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response[\"EndpointStatus\"]\n",
    "    if status in [\"InService\", \"Failed\"]:\n",
    "        print(f\"Endpoint Status: {status}\")\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "# Check if deployment was successful\n",
    "if status != \"InService\":\n",
    "    raise Exception(f\"Deployment failed with status: {status}\")\n",
    "\n",
    "print(f\"Model deployed successfully at endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4cc68-141b-4e6e-a920-66d5abf549af",
   "metadata": {},
   "source": [
    "## Send an async query to the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c8576-e413-4d4f-a452-88e3e1085db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke Asynchronous Inference\n",
    "s3_async_input_uri = f\"s3://{s3_bucket}/{s3_async_input_key}\"\n",
    "print(s3_async_input_uri)\n",
    "\n",
    "sagemaker_rt_client = boto3.client(\"sagemaker-runtime\")\n",
    "response = sagemaker_rt_client.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name,\n",
    "    InputLocation=s3_async_input_uri\n",
    ")\n",
    "\n",
    "# Get Inference ID\n",
    "inference_id = response[\"InferenceId\"]\n",
    "print(f\"Submitted async inference request. InferenceId: {inference_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a319db-a1d0-4a92-aca4-87ba52969011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the results and display\n",
    "\n",
    "# Construct Output S3 Path\n",
    "s3_output_uri = f\"s3://{s3_bucket}/{s3_async_output_prefix}/{inference_id}.out\"\n",
    "print(s3_output_uri)\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "bucket = s3_resource.Bucket(s3_bucket)\n",
    "\n",
    "print(\"Waiting for async inference results...\")\n",
    "\n",
    "while True:\n",
    "    objects = list(bucket.objects.filter(Prefix=s3_output_uri))\n",
    "    if objects:\n",
    "        print(f\"Output file found: {s3_output_uri}\")\n",
    "        break\n",
    "    time.sleep(5)  # Wait and retry\n",
    "\n",
    "# Download and Read Output File\n",
    "output_filename = f\"output_{uuid.uuid4().hex}.csv\"\n",
    "s3_client.download_file(s3_bucket, s3_output_uri, output_filename)\n",
    "\n",
    "print(f\"Downloaded inference output to: {output_filename}\")\n",
    "\n",
    "# Display Results\n",
    "output_df = pd.read_csv(output_filename, header=None)\n",
    "print(\"Inference Results:\")\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd83c3b-c954-4343-b092-24bc26b01678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
