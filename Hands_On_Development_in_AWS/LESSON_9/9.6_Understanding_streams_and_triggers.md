# 9.6 Understanding streams and triggers 
 
 # DynamoDB Streams and Lambda Trigger Demo

## Overview

This lesson demonstrates how to:
- Create a DynamoDB table with streams enabled
- Configure a Lambda function to process stream events
- Modify IAM roles to grant necessary permissions
- Observe stream-triggered Lambda executions via CloudWatch logs

---

## Step 1: Create DynamoDB Table

- Go to **DynamoDB** service
- Create a table named `trigger-demo`
  - Partition key: `ID` (String)
  - Sort key: `name` (String)
- Use default settings
- Wait for the table to become active

---

## Step 2: Enable Streams

- Navigate to **Exports and Streams** tab
- Enable stream with option: `New and old images`
- Confirm stream creation
- Note: No triggers are associated yet

---

## Step 3: Create Lambda Function

- Go to **Lambda** service
- Use blueprint: `dynamodb-process-updates`
  - Runtime: Node.js
- Function name: `DDBTriggerDemo`
- Create a new role: `DDBTriggerDemoRole`
- **Do not add trigger yet** (role lacks necessary permissions)

---

## Step 4: Modify IAM Role

- Go to **IAM** > Roles
- Locate `DDBTriggerDemoRole`
- Attach policy: `AWSLambdaDynamoDBExecutionRole`
  - Grants permissions:
    - `DescribeStream`
    - `GetRecords`
    - `GetShardIterator`
    - `ListStreams`
- Role now has:
  - Basic Lambda execution policy
  - DynamoDB stream access policy

---

## Step 5: Add Trigger to Lambda

- Go back to Lambda function
- Add trigger:
  - Source: DynamoDB
  - Table: `trigger-demo`
  - Batch size: `100`
  - Starting position: `LATEST`
- Confirm trigger is enabled

---

## Step 6: Insert and Modify Items

- Insert items into `trigger-demo` table:
  - `ID: 1`, `name: Tom Smith`
  - `ID: 2`, `name: John Smith`
  - `ID: 3`, `name: Alice Graham`

- Modify item:
  - Change `Tom Smith` to `Tom Smith II`
  - Note: Changing key causes deletion and recreation

---

## Step 7: View Logs in CloudWatch

- Go to Lambda > Monitor > View logs in CloudWatch
- Select latest log stream
- Observe:
  - `eventID`
  - `eventName`
  - `newImage` and `oldImage` (if applicable)

- Update Lambda code:
  - Uncomment `console.log(JSON.stringify(record))`
  - Deploy updated function

---

## Step 8: Validate Stream Behavior

- Modify item again:
  - Add attribute: `testNumber: 123`
- Check CloudWatch logs:
  - Confirm presence of both `newImage` and `oldImage`
  - Demonstrates stream capturing updates

---

## Summary

✅ Created DynamoDB table with streams  
✅ Enabled stream for new and old images  
✅ Created Lambda function using blueprint  
✅ Modified IAM role for stream access  
✅ Added DynamoDB trigger to Lambda  
✅ Inserted and modified items to trigger events  
✅ Verified stream events in CloudWatch logs

---

## Key Takeaways

- DynamoDB streams can capture item-level changes
- Lambda triggers can process these changes in real-time
- IAM roles must be properly configured for stream access
- Stream type `new and old images` enables full change tracking
- CloudWatch logs provide visibility into trigger execution


 
 
 ## [Context](./../context.md)