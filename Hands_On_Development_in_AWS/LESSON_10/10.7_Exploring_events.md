# AWS S3 Event Notifications and Lambda Integration Demo

This demo walks through configuring **Amazon S3 event notifications** to automatically trigger an **AWS Lambda function** whenever an object is uploaded to an S3 bucket. The example simulates a use case where a user uploads a photo that triggers a Lambda function to process or resize the image and store it in another bucket.

---

## 1. Use Case Overview

**Scenario:**  
A user takes a photo on their phone, which is uploaded to an **S3 bucket**.  
This upload event triggers a **Lambda function** that resizes the image and stores the processed version in another S3 bucket.

This workflow demonstrates **event-driven architecture** using **S3 event notifications** and **AWS Lambda**.

---

## 2. Setting Up S3 Event Notifications

1. Navigate to the **S3 bucket** (e.g., `mylittlebucket-nova` in the *us-east-1* region).
2. Go to **Properties â†’ Event Notifications**.
3. Click **Create event notification**.
4. Configure the event:
   - **Event name:** e.g., `ImageUploadEvent`
   - **Filter (suffix):** `.jpg` or `.png` â€” this ensures only images trigger the function.
   - **Event type:** *All object create events* (e.g., `PUT`, `POST`).
   - **Destination:** Select **Lambda function**.

> ðŸ”¸ **Tip:**  
> Prefixes and suffixes allow filtering events by file path or file type.  
> Example: Suffix `.png` ensures only PNG files trigger the function.

---

## 3. Avoiding Recursive Lambda Execution

> âš ï¸ **Important Warning:**
> Never configure your Lambda to write back into the **same bucket** that triggers it.

If you upload to and write back into the same bucket:
- Each new object creation re-triggers the Lambda function.
- This creates **infinite recursive executions**.
- You will incur **significant costs** due to repeated Lambda invocations.

To prevent this:
- Use a **different destination bucket** for Lambda output.
- Disable recursive triggers by ensuring event filters do not overlap with Lambda outputs.

---

## 4. Creating a Lambda Function

1. Go to the **AWS Lambda** service and click **Create function**.
2. Choose **Blueprints â†’ S3 Events**.
   - Select the blueprint: `s3-get-object (Node.js)`.
3. Configure the function:
   - **Function name:** `S3EventDemo`
   - **Execution role:** Create new role from policy templates â†’ `S3EventRole1234LambdaRole`
   - **Policy template:** *Simple microservice permissions to read from S3.*
4. Set the **trigger**:
   - **Source:** S3
   - **Bucket:** `mylittlebucket-nova`
   - **Event type:** *All object creation events*
   - Leave prefix and suffix blank (applies to all objects).

> If you use the same bucket for input and output, AWS requires acknowledging a warning about **recursive invocation**.

---

## 5. Function Code Overview

The example Lambda blueprint code (Node.js):

```javascript
const AWS = require('aws-sdk');
const s3 = new AWS.S3();

exports.handler = async (event) => {
    console.log('Received event:', JSON.stringify(event, null, 2));

    const bucket = event.Records[0].s3.bucket.name;
    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));

    const params = { Bucket: bucket, Key: key };
    try {
        const data = await s3.getObject(params).promise();
        console.log("CONTENT TYPE:", data.ContentType);
        return data.ContentType;
    } catch (err) {
        console.error(err);
        throw err;
    }
};
